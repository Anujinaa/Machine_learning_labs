{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 15-16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-T1zgYq_sEQ"
      },
      "source": [
        "# Mongolian News Classification\n",
        "\n",
        "This notebook contains a simple demo classifying the [Eduge news dataset](https://github.com/tugstugi/mongolian-nlp) provided by [Bolorsoft LLC](https://bolorsoft.com/) using a SVM and [SentencePiece](https://github.com/google/sentencepiece).\n",
        "\n",
        "## Download Eduge dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oRzVjcQ7xdGi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "if not exists(\"eduge.csv\"):\n",
        "  !wget -q https://github.com/tugstugi/mongolian-nlp/raw/master/datasets/eduge.csv.gz\n",
        "  !gunzip eduge.csv.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc7Q18GdAoKN"
      },
      "source": [
        "## Download SentencePiece vocabulary\n",
        "\n",
        "A SentencePiece model trained on a Mongolian corpus containg 650M words will be used the text tokenizer. We will download it from the repo [tugstugi/mongolian-bert](https://github.com/tugstugi/mongolian-bert):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fTY_S9iHxl_4"
      },
      "outputs": [],
      "source": [
        "if not exists('mn_uncased.model'):\n",
        "  # download both SentencePiece models: cased and uncased\n",
        "  !wget -q https://github.com/tugstugi/mongolian-bert/raw/master/sentencepiece/mn_cased.model\n",
        "  !wget -q https://github.com/tugstugi/mongolian-bert/raw/master/sentencepiece/mn_cased.vocab\n",
        "  !wget -q https://github.com/tugstugi/mongolian-bert/raw/master/sentencepiece/mn_uncased.model\n",
        "  !wget -q https://github.com/tugstugi/mongolian-bert/raw/master/sentencepiece/mn_uncased.vocab\n",
        "    \n",
        "  # install SentencePiece\n",
        "  !pip install -q sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9Ao4LXDCH1L"
      },
      "source": [
        "## Load SentencePiece and test\n",
        "\n",
        "Load the downloaded SentencePiece model and tokenize some text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wIPCSjHFyQvU",
        "outputId": "a4fcb133-b23e-4ecb-8229-5d916de85749"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'▁мөнгөө ▁тушаа чихсан ыхаа ▁дараа ▁мэдэгд ээрэй'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sentencepiece as spm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from sklearn.feature_extraction.text import *\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.Load('mn_uncased.model')\n",
        "def sp_tokenize(w):\n",
        "  return sp.EncodeAsPieces(w)\n",
        "\n",
        "\" \".join(sp_tokenize('Мөнгөө тушаачихсаныхаа дараа мэдэгдээрэй'.lower()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPS3zFeyCiNy"
      },
      "source": [
        "## Train/Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRvYlCAoytvf",
        "outputId": "ce89633f-5aa8-414a-9eef-f279f8255a25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "labels ['урлаг соёл', 'эдийн засаг', 'эрүүл мэнд', 'хууль', 'улс төр', 'спорт', 'технологи', 'боловсрол', 'байгал орчин']\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"eduge.csv\")\n",
        "df = df.rename(columns=lambda x: x.strip())\n",
        "\n",
        "# show labels\n",
        "print('labels', df['label'].unique().tolist())\n",
        "\n",
        "# stratified train and test split\n",
        "train, test = train_test_split(df, test_size=0.1, random_state=999, stratify=df['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qClJ6pA-C84c"
      },
      "source": [
        "## Train SVM\n",
        "\n",
        "Now train a SVM, no hyperparameter optimization, use only some default parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bhve5JIHzF9l"
      },
      "outputs": [],
      "source": [
        "text_clf = Pipeline([('vect', CountVectorizer(tokenizer=sp_tokenize, lowercase=True)),\n",
        "                         ('tfidf', TfidfTransformer()),\n",
        "                         ('clf', AdaBoostClassifier())])\n",
        "                         #('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-4, random_state=0))])\n",
        "\n",
        "t = time.time()\n",
        "text_clf = text_clf.fit(train['news'], train['label'])\n",
        "t = time.time()-t\n",
        "print(\"Training time in seconds: \", t)\n",
        "\n",
        "t = time.time()\n",
        "predicted = text_clf.predict(test['news'])\n",
        "t = time.time()-t\n",
        "print(\"Prediction time in seconds: \", t)\n",
        "\n",
        "print(\"Feature count:\", len(text_clf.named_steps['vect'].vocabulary_))\n",
        "print(\"Classifier accuracy: \", np.mean(predicted == test['label']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgtKXVZjwrnj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Eduge_SVM_baseline.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
